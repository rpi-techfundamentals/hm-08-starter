{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Text Modeling and TensorFlow Learn\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All).  You can speak with others regarding the assignment but all work must be your own. \n",
    "\n",
    "\n",
    "### This (plus Separate Spark Part) is a  30 point assignment graded from answers to questions and automated tests that should be run at the bottom. Be sure to clearly label all of your answers and commit final tests at the end. If you attempt to fake passing the tests you will receive a 0 on the assignment and it will be considered an ethical violation. (Note, not all questions have tests).\n",
    "\n",
    "#### 20 points for this Notebook and 10 points for the Spark notebook. \n",
    "\n",
    "\n",
    "### You must show the executed code and then the output . Do not just copy and past the code to a markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = [\"Alyssa Hacker\"]  #You can speak with others regarding the assignment, but all typed work must be your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext ipython_unittest\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Data is From Kickstarter\n",
    "If you don't know Kickstarter, take a few minutes to take a look on the [website](http://www.kickstarter.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will fail. Read on to find why.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('kickstarter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The below code should work. Explain what the `encoding` term means.  We actually didn't talk much about in class, but it is one of those things that pops up quite frequently when working with text data. OK here is a start. \n",
    "[Encoding](https://www.w3.org/International/questions/qa-what-is-encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should work. \n",
    "df = pd.read_csv('kickstarter.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at the data.\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `state` is the variable of interest. This indicates whether a Kickstarter campain has succeeded or failed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nex we are going to generate counts by state, which appears to be the most interesting DV. \n",
    "df.groupby(['state']).agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A couple independent variables are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nex we are going to generate counts by state, which appears to be the most interesting DV. \n",
    "df.groupby(['spotlight']).agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nex we are going to generate counts by state, which appears to be the most interesting DV. \n",
    "<insert text to view each country by count>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nex we are going to generate counts by state, which appears to be the most interesting DV. \n",
    "<insert text to view disable_communications by count>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2). Create `blurb_new` and `name_new` with just the words.  I got you most of the way there but make it **lowercase**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3). Replace the `-` with a space for the slug term and remove any additional spaces (so there is only 1 space between).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK I'm going  \n",
    "import re\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "regex2= re.compile('\\s+')\n",
    "regex3 = re.compile('-')\n",
    "#First parameter is the replacement, second parameter is your input string\n",
    "df['blurb_new'] = df['blurb'].apply(lambda x: regex.sub('', str(x)()))\n",
    "df['blurb_new'] = df['blurb_new'].apply(lambda x: regex2.sub(' ', str(x)()))\n",
    "#<Fix slug>\n",
    "#<Fix newname>\n",
    "#df[['name_new','blurb_new','slug_new']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4). Create a count vectorizer called count_slug for the `slug_new` field. Create a dictionary `vocab_count` to include the count for each word in the corpus (example shown below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<create a count vectorizer>\n",
    "vocab_count=count_vectorizer.vocabulary_\n",
    "vocab_count['cybersecurity']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5). Create a TFIDF vectorizer called `tfidf_vectorizer_blurb` using the `blurb_new` field. Create a dictionary `vocab_tfidf` to include the count for each word in the corpus (example shown below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<create a tfidf\n",
    "vocab_tfidf=tfidf_vectorizer.vocabulary_\n",
    "vocab_tfidf['cybersecurity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Getting Started with Tensorflow Learn\n",
    "Tensorflow is a little bit senstive as to the data that goes in, which has to be integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du1=pd.get_dummies(df['spotlight'], drop_first=True)\n",
    "du2=pd.get_dummies(df['country'], drop_first=True)\n",
    "X_train = pd.concat([du1, du2], axis=1, join='inner').values\n",
    "\n",
    "#This is a raw matrix of integers. \n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This changes our DV to integers\n",
    "df['state']=pd.Categorical(df['state'])\n",
    "y_train=df['state'].cat.codes.real.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with Tensorflow Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # not shown in the config\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "# List of hidden units per layer. All layers are fully connected. Ex. [64, 32] means first layer has 64 nodes and second one has 32.\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=5,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\n",
    "dnn_clf.fit(X_train, y_train, batch_size=50, steps=4000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = dnn_clf.predict(X_train)\n",
    "#This calculates the accuracy.\n",
    "accuracy_train=metrics.accuracy_score(y_train,  y_pred['classes'])\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(y_train,  y_pred['classes']) )\n",
    "\n",
    "#0.947420882133"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Update the Analysis above to include  'is_starrable' as one of the independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge! (not for points)\n",
    "\n",
    "Figure out how to include the text as independent variables through the TFIDF vectorizer.  If you take up the challenge, post the solution to @lack. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests.\n",
    "Please run all tests before submitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%unittest_main\n",
    "class TestHomework8(unittest.TestCase):\n",
    "    def test_text1(self):\n",
    "        self.assertEqual(df['blurb_new'][2], 'automatically opens your garage door when you come home open close and monitor your garage door from your phone')\n",
    "    def test_text2(self):\n",
    "        self.assertEqual(df['slug_new'][2], 'garage beacon ibeacon enabled garage door opener')\n",
    "    def test_text3(self):\n",
    "        self.assertEqual(df['name_new'][2], 'garage beacon turn your phone into a garage door remote')\n",
    "    def test_text4(self):\n",
    "        self.assertEqual(vocab['cybersecurity'], 1717) \n",
    "    def test_text5(self):\n",
    "        self.assertEqual(vocab_tfidf['cybersecurity'], 2340) \n",
    "    def test_text6(self):\n",
    "        self.assertAlmostEqual(accuracy_train,0.947420882133)    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
